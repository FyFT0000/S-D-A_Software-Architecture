https://www.coursera.org/learn/software-architecture?specialization=software-design-architecture

Software Architecture
    Ways architectures are represented, both in UML and other visual tools. Most common architectures, their qualities, and tradeoffs.


3.1.1 – Architecture Overview and Process
Software architecture is the fundamental design of an entire software system. It defines what elements are included in the system, what function each element has, and how each element relates to one another. It is the big picture or overall structure of the whole system—how everything works together.
_   It follows that to design a software system, a software architect has to take many factors into consideration:
    _the purpose of the system,
    _the audience or users of the system,
    _the qualities that are of most importance to users, and
    _where the system will run.
_   Software architecture is important, particularly for large systems. If there is a clear design of the overall system from the start, there is a solid basis for developers to follow. Each developer will then know what needs to be implemented and how things are related to meet desired needs efficiently. This avoids conflicts, duplication, and ad hoc unnecessary work.
_   Some advantages of software architecture include:
    _higher productivity for the software team, as a well-defined structure helps to coordinate work, implement individual features, or guide discussions on potential issues.
    _improved evolution for the software, since design principles are applied to make changes easier to accomplish or defects easier to find.
    _enhanced quality in the software by carefully considering the needs and perspectives of all the stakeholders.
_   Software architecture typically have the following stakeholders:
    _Software developers: Software architecture helps developers create and evolve software by providing strong direction and organization on what needs to be done.
    _Project Managers: Software architecture provides useful information to project managers to help them identify possible risks and to manage the project successfully. Software architecture helps project managers to understand task dependencies and impacts of change and to coordinate work assignments.
    _Clients: Clients make important decisions about the system, like its funding. Software architecture establishes a basis for communication with clients, so they understand what they are paying for and that their needs are met.
    _End users: Users may not care how the software is actually designed, but they do care that it “works well” for them.

3.1.2 – Kruchten's 4 + 1 Model View
This model is a way of understanding the key considerations or important perspectives that need to be addressed in software architecture.
_   Logical View: focuses on the functional requirements of a system, usually involves the objects of the system. From these objects, a UML class diagram can be created to illustrate the logical view.
    _A class diagram establishes the vocabulary of the problem and resulting system. By defining all of the classes, their attributes, and their behaviours it becomes easy to understand the key abstractions and terminology. Class diagrams are also useful for specifying database schemes. The class diagram makes it easier to see how classes interact and how data should relate to each other in a database.
    _Some of the most effective UML diagrams related to the logical view of a system are the class diagram and the state diagram. Both the class diagram and the state diagram focus on the classes and objects of a system.
_   Process View: focuses on achieving non-functional requirements. These are the requirements that specify the desired qualities for the system, which include quality attributes such as performance and availability. The process view also presents processes that correspond to the objects in the logical view.
    _Some of the most effective UML diagrams related to the process view of a system are the activity diagram and the sequence diagram. The activity diagram can illustrate the processes or activities for a system. The sequence diagram shows how objects interact with one another, which involves how methods are executed and in what order.
_   Development View: describes the hierarchical software structure. It also considers elements such as programming language, libraries, and toolsets. It is concerned with the details of software development and what is involved to support that. This extends to management details such as scheduling, budgets, and work assignments. Essentially, the development view covers the hierarchical software structure and project management.
_   Physical View: handles how elements in the logical, process, and development views must be mapped to different nodes or hardware for running the system.
    _One of the most effective UML diagrams related to the physical view of a system is the deployment diagram. It can express how the pieces of a system are deployed onto hardware or execution environments.
_   Scenarios: align with the use cases or user tasks of a system and show how the four other views work together. For each scenario, there is a script that describes the sequence of interactions between objects and processes. This involves the key objects defined in the logical view, the processes described in the process view, the hierarchy identified in the development view, and the different nodes specified in the physical view. Scenarios relate these elements to provide a complete picture.
_   None of the views are fully independent of each other, with elements of some views connected to others. The 4+1 view model can be molded to fit many situations to understand the architecture of a software system. Being able to see a complex problem in many different perspectives helps make your software more versatile.

3.1.3 – UML Component Diagram
Are concerned with the components of a system.
_   Components are the independent, encapsulated units within a system. Each component provides an interface for other components to interact with it. Component diagrams are used to visualize how a system’s pieces interact and what relationships they have among them.
_   Component diagrams are different from most other diagrams, as they show high-level structure and not details like attributes and methods. They are purely focused on components and their interactions with each other. Component diagrams are a static view of the software system, and depict the system design at a specific point in its development and evolution. The basis of component diagrams focuses on the components and their relationships. Each component in a diagram has a very specific relationship to the other components through the interface it provides.
_   Component diagrams have:
    _Ball connectors: which represent a provided interface. A provided interface shows that a component offers an interface for others to interact with it. The provided interface means that client and consumer components have a way of communicating with that component.
    _Socket connectors: that display a required interface. The required interface is essential to the component diagram, to show that a component expects a certain interface. This required interface is to be satisfied or provided by some other component.
    _Assembly relationship: occurs when one component’s provided interface matches another component’s required interface. The provided interface is depicted by a ball, and the required interface is depicted by a socket.
_   To build a component diagram:
    _First, you must identify the main objects used in the system.
    _Next, the relevant libraries for the system need to be identified.
    _Finally, the relationship between these components would need to be identified. When relevant libraries are identified, this extends to third-party implementation dependencies, which should also be integrated into the diagram where relevant.
_   Component diagrams are especially useful early in the design process, because of its high-level emphasis. They can be drawn at different levels and allows you to focus not only on systems but on subsystems as well.

3.1.4 – UML Package Diagram
Show packages and the dependencies between them.
_   These diagrams can organize a completed system into packages of related packageable elements, which could include data, classes, or even other packages. Package diagrams help provide high-level groupings of a system so that it is easy to see how a package contains related elements as well as how different packages depend on each other.
_   A package groups together elements of software that are related. Elements can be related based on data, classes, or user tasks. A package can also define a “namespace” for elements it contains, that is, a package is named and can organize the named elements of software into a separate scope. An element can be uniquely identified in the system by a fully “qualified name” that is based on its own name and the name of the package that the element is in.
_   Packages are depicted by tabbed folders. If there are no elements to show in the package, then the package name goes into the centre of the folder. If details are needed, there are two ways this can be expressed: The elements can be nested within the folder. Alternately, oyher notation can be used. Contained elements can also be listed in a package by their names. These names can be partially qualified, but they should be unique within the package.
_   Relationships are denoted through dotted-line
arrows:
    _A package can <<import>> an element from another package or can import the entire contents of other packages. Import tag is public.
    _A package can do a private import, as indicated by the <<access>> tag
    _A package can <<uses>> relationship also. Implies that the package requires other for its full implementation.
    _Packages can also be <<merge>>. Merging typically occurs when two packages or concepts need to come together into one. This is a use of generalization that allows different definitions to be provided for the same concept.
_   Package diagrams can be created at any stage of development. They can also adapt and change with the latest version of software being worked on. Package diagrams are particularly useful for technical designers because they allow them to see the dependencies and relations between groups of related elements.

3.1.5 – UML Deployment Diagram
Are used to visualize the deployment details of a software system. The diagrams include more than just code, but also separate libraries, an installer, configuration files, and many other pieces. In order for software to be ready to run, it is necessary to understand all the files and executables involved and the environments where they reside.
_   The deployment environment, or deployment target, can be very specific and involve particular hardware devices. It can also be very general and involve supported operating systems. Details in a deployment diagram change accordingly. For example, software developed for Linux, MacOS or Windows may have differences from one another.
_   Deployment diagrams deal with artifacts. Artifacts are a physical result of the development process. Artifacts for a video game might include things like an executable to run the game, an installer to install the game, audio libraries for sound, and multimedia assets. These are created as outcomes of producing the system and are the final pieces to be put together.
_   There are two different types of deployment diagrams:
    _Specification-level diagrams: provides an overview of artifacts and deployment targets, without referencing specific details like machine names. It focuses on a general overview of your deployment rather than the specifics.
    _Instance level diagrams: is a more specific approach that maps specific artifacts to specific deployment targets. They can identify specific machines and hardware devices. This approach is usually used to highlight the differences in deployments among development, staging, and release builds.
_   When creating deployment diagrams, it is important to use the correct notation for the various elements:
    _Nodes: are deployment targets that contain artifacts available for execution.In a deployment diagram, they look like 3D boxes. Hardware devices are also displayed as 3D boxes, only they have a “device” tag on them to differentiate them.
    _Relationships can be represented as a solid line between two nodes, that shows a relationship between deployment targets. The line shows that the two nodes have a communication path between them. This relationship typically identifies a particular communication protocol.
        _Manifestation is a relationship where an artifact is a physical realization of a software component. It can be represented with a “manifests” indicatr.
_   If an artifact is drawn inside a node box, this shows that an artifact is deployed to a node. This also means that the artifact cannot function without this deployment target.
_   In a deployment diagram, there is a distinct hierarchy of deployment targets. This hierarchy is very important. You should start from the highest level of your deployment information, from application name down to device and operating system.
_   Deployment diagrams help provide consistency and organization to deployments, which helps avoid system failures. The diagrams also help keep track of the files and executables needed to deploy and run the software. The diagram can be on an instance level specific to the deployment machines you are using, or it can be general for a range of execution environments.

3.1.6 – UML Activity Diagram
Allows the representation of the control flow from activity to another in a software system. It captures the dynamic behaviour of the system and allows the mapping of branching into alternative flows.
_   Activities: are actions that further the flow of execution in a system. They are actions that when completed cause another action to execute. For example, an action can alter or create new objects. These changes or actions can drive your application forward. In order to create an activity diagram, you must:
    _1. Identify the activities.
    _2. Identify the respective conditions of the system’s activities.
_   There are a few major parts to an activity diagram:
    _Start and End: notes that look like labelled circles. These circles are where the diagram must begin. They show the starting activity that initializes the control flow of the application. The end node shows the final activity of the diagram.
    Intermediate activities are shaped like an oval, and they describe all of the activities that change the game state before the game ends.
    _Decision nodes: are diamonds that have an activity leading into it, and there is the possibility of two alternative outcomes as the next activity. The choice of outcome depends on how the condition on the decision node evaluates.
    _Partitions: divide activities up into different categories.
such as where it occurs, or the user role involved. 
_   All essential activities must be included in a diagram as well as the conditions.
_   Activity diagrams allow the mapping of concurrent activities that happen in parallel. A fork in the flow moves into parallel flows, so activities can happen at the same time. Parallel flows can join into a single flow. To denote this, activity diagrams can use a separate swimlane for each flow denotating Partitions. Swimlanes can also divide activities up into different categories, such as where it occurs or the user role involved. Arrows crossing each lane show how different activities of a system interact across categories.
_   Activity diagrams allow you to see what activities and conditions should be included in a system. As well, from the diagrams you see the order in which features are encountered while also allowing for alternate flows to be taken into account for the system.

Language-Based Systems
The programming paradigm of the language selected to implement a system will affect the architectural style of that system. Each programming paradigm has its own set of constructs, principles, and design patterns, and their use shapes the system being created. This section focuses on object-oriented architectural styles, which result from object-oriented programming paradigms.

S1 - 3.2.1 – Abstract Data Types and Object-Oriented (Language-Based Systems)
Object-oriented design architectural styles are focused on the data. When modelling a system in object-oriented design, begin by looking at the different kinds of data handled by the system to see how the system can be broken down into abstract data types.
_   Abstract data type: can be represented as a class that you define to organize data attributes in a meaningful way, so related attributes are grouped together along with their associated methods. Encapsulation restricts access to the data and dictates what can be done with it.
_   Object-oriented refers to a system composed of objects where each object is an instance of a class. In other words, the type of each object is its class. Objects may interact with each other through the use of their methods. The object-oriented paradigm allows for inheritance among abstract data types. This means that one abstract type can be declared an extension of another type.
_   These classes themselves form a language-based architecture that arises from basic object-oriented principles. The classes within the system will determine the overall structure of the system. In other words, the overall object-oriented architectural style of a system directly follows from the fact that an object-oriented approach was used in development.
_   Some problems are well suited to an object-oriented architectural style. However, not all situations will have easily identifiable classes. In some situations, another design choice may be better suited for the problem at hand. In a system centered around scientific computation, the identification of classes may result in unnecessary complexity, and in turn, lower performance.

3.2.2 – Main Program and Subroutine (Language-Based Systems)
Main program and subroutine architectural styles are focused on functions. They develop from a procedural programming paradigm. C is an example of a language that follows this paradigm.
_   In a main program and subroutine architectural style, a system is modelled by breaking up the overall functionality of the system into a main program and subroutines. Subroutines are connected by procedure calls, and they may have nested calls. In nested calls, subroutines may call other subroutines, which may call yet more subroutines, and so on. This means that the structure of the resulting code is not flat, but rather it is hierarchical, so it can be modelled as a directed graph. The structure of the subroutines that build up the system affect the structure of the system as a whole. The subroutines declared in the code are structure as a big “call tree”.
_   In this paradigm, data is stored as variables. Abstract data types are supported in procedural programming; however, inheritance is not explicitly supported. Under this paradigm, it is not easy to make one abstract type an extension of another. The main focus of this paradigm is therefore on the behaviour of functions and how data moves through those functions. The main program and subroutine architectural style is best suited for computation-focused systems.
_   Each subroutine may have its own local variables. A subroutine has access to all data within its scope. To access data outside its scope, data may be passed into the subroutines as parameters, by value or by reference, and data may be passed out of a subroutine as a return value.
_   This architectural style promotes modularity and function reuse, which results in certain advantages. When functions are well defined and do not produce side effects, they are considered like “black boxes.” Given an input, they will always have the same output. Further, library functions are easily integrated into programs.
_   There are also certain disadvantages from this style. Subroutines may mutate data in unexpected ways. A subroutine may be affected by data changes made by another subroutine during execution. This issue is especially true for global data shared across subroutines. Changes to data can be unpredictable and result in a function receiving an input that it was not expecting, or even an input that it is not capable of handling correctly, which can result in run-time errors.
_   Procedural programming paradigms are well suited to systems centred around computation, such as spending management programs. Identifying object-oriented components of these kinds of systems can be difficult and result in overly complex solutions. However, for problems where abstract data types with modelling make the solution easier, then object-oriented architectural styles are more well suited.

Repository-Based Systems
Modern software systems rarely operate in isolated environments. As a software developer, any software architecture you create needs to be capable of sharing information between separate components.
To solve (the state of a component is only temporary while the component is running, and save information in files that are not the best way to transfer data between components) a data-centric software architecture can be used. This architecture allows data to be stored and shared between multiple components, thus increasing the maintainability, reusability, and scalability of the system. This architecture can be achieved by integrating a method of shared data storage, such as a database, into the overall system design.
At the core of a data-centric architecture are two types of components:
    _Central data: is the component used to store and serve data across all components that connect to it.
    _Data accessors: are the components that connect to the central data component. The data accessors make queries and transactions against the information stored in the database.

3.2.3 – Databases (Repository-Based Systems)
Central data is often stored in a database.
_   Databases ensure several data qualities, which are important to data-centric architectures. These are:
    _Data integrity: A database ensures that data is accurate and consistent over its lifespan.
    _Data persistence: A database ensures that data will live on after a process has been terminated—databases can save data from any number of components.
_   One way that databases store information is by using tables. Relational databases are a type of database that uses tables. Each table represents an abstraction.
_   Relational databases use Structured Query Language (SQL) to query or “ask” the database for information and to perform transactions or “tell” the database to do something. These abilities allow for information to be shared through a database between data accessors.
_   The management and optimization of queries and transactions can be automated by a data base management system (DBMS), so integrating a database into a system is simplified.
_   In data-centric architectural design, the central data is passive. Central data is primarily concerned with storing and serving information, not with heavy data processing or large amounts of business logic.
_   Data accessors: are any component that connects to a database, which is characterized by its abilities to:
    _Share a set of data, while being able to operate independently.
    _Communicate with the database through database queries and transactions. Data accessors do not need to interact directly with each other and therefore do not need to know about each other.
    _Query the database to obtain shared system information. This is used to get data in order to perform computations.
    _Save the new state of the system back into the database using transactions. Data is stored back into the database once the data accessor has finished its processing.
_   A data accessor contains all the business rules required to perform its functions. This means that this software architecture enables you to separate concerns into different, specialized data accessors. Also, use of the data accessors can be controlled, so an end user only has permission for the ones they need on a day-to-day basis.
_   Data-centric architecture presents many advantages over a basic object-oriented system, because of the integration of a centralized database. These advantages include:
    _Increased support of data integrity, data backup, and data restoration.
    _Reduced overhead for data transfer between data accessor, as data accessors do not need to be concerned with talking to one another—the database communicates for them,
    _A system that can be easily scaled up, as data accessors are functionally independent, so additional features can be added without having to worry about affecting others.
    _Central data components usually “live” on a separate server machine with sufficient disk storage dedicated to the database, which allow for easier management of information.
_   Data-centric architecture also presents disadvantages. Integrating a database can disadvantage a system in the following ways:
    _The system is heavily reliant on the central data component, so if it becomes unavailable or if the data corrupts, then the entire system is affected. Safeguards such as data redundancies that replicate data on separate hard disks can be costly.
    _Data accessors are dependent on what gets stored in the database. New data accessors need to build around the existing data schema. Anything that isn’t stored needs to be computed, or if there is no matching column or table for a specific data need, then the database cannot be used.
    _It is difficult to change the existing data schema, particularly if a large amount of data is already stored. Further, data schema changes will affect data accessors.
_   In summary, data-centric software architecture is a commonly used design by many companies. They allow large amounts of data to be stored and managed in a central data repository, making a system more stable, reusable, maintainable, and exhibit better performance. They also separate the functionality of data accessors, so it is easier to scale the system. Finally, they also facilitate data sharing between data accessors through database queries and transactions.

3.2.4 – Layered Systems
In software, a layer is a collection of components that work together towards a common purpose. The key characteristic of a layered architecture is that the components in a layer only interact with components in their own layer or adjacent layers. When an upper layer interacts with the layer directly below it, it cannot see any of the deeper layers.
_   Usually, the inner or bottom layer provides services or abstractions for the layer outside or above it. The interfaces provided by the components of a layer should be well defined and driven by the needs of the system.
_   Layering allows for applying “separation of concerns” into each of the layers. Many layered systems are split into “presentation,” “logic,” and “data” layers.
_   An operating system for a computer is a common example of a layered system:
    _The kernel is the core of the operating system. One of its main responsibilities is to interface with the hardware and allocating resources.
    _Above the kernel layer is the system and application libraries layer. This layer provides the higher-level functions for saving files or drawing graphics.
    _Above this layer is the utilities and applications layer, which to most users is the operating system. Utilities are tools included with the operating system, such as command-line programs.
_   Advantages of layered systems include the fact that:
    _Users can perform complex tasks without needing to understand the layers below.
    _Different layers can be run at different levels of authorization or privilege. Typically, the top layer is considered the “user space” that does not have authority to allocate system resources or communicate with hardware directly. This “sandboxing” provides security and reliability to the kernel.
    _Designs will be more loosely coupled, as layered architecture follows the principle of least knowledge.
_   There are certain trade-offs to be aware of in layered systems. Most notably, enforcing layers has an efficiency trade-off. If only adjacent layers can communicate, then the system will likely have some interactions that pass through one layer to the next, and sometimes information must be shared between layers that are not adjacent. This extra communication adds complexity and uses up processing resources.
_   Overhead must be balanced against the separation of concerns gained from enforcing layers. If most communication is passing directly through a layer, then the design may need to be relaxed, or a different architecture may be better suited to the problem. If only a small amount of communication is passed through, then a layered system may be a good choice. Layered architecture can be relaxed by allowing for passthrough. In a diagram, this is shown as a notch in the layer.
_   In summary, layered architecture:
    _It can be intuitive and powerful. Many organizations and solutions have layered structures, so it is easy to apply layered architecture where appropriate.
    _It supports the separation of concerns, because each layer is a set of components with similar responsibility or purpose.
    _It is modular and loosely coupled, as each layer only communications with one or two other layers, allowing for different implementations to be easily swapped.
    _It can be adapted so that layering is not always strict, which helps manage design complexity or provide a starting point for structuring the system.

3.2.5 – Client Server n-Tier
n-Tier or multitier architectures are related to layered architectures. Tiers refer to components that are typically on different physical machines. Although the terms “tier” and “layer” are used interchangeably, they are not the same thing. n-Tier or multitier architectures are layered architectures based on tiers.
_   The number of tiers in an n-Tier architecture can vary, although three-tier and four-tier architectures are common. The relationship between two adjacent tiers in an n-Tier architecture is often a client/server relationship. In a client/server relationship, one program (the server) provides services such as storing information in a database or performing computation tasks upon request from another program (the client). This communication is known as the request-response. A tier can act as both a server and a client, fulfilling the requests of its clients and making requests of its servers at the same time.
_   Client-host and server-host refer to machines that host client software and server software respectively.
_   Request-response relationships can be:
    _A synchronous request-response relationship is one where the client sends a request, then awaits the server’s response before continuing execution. In UML, synchronous messages are depicted with a closed arrowhead. Servers do not always respond quickly, so a synchronous message may cause the client user interface to freeze while waiting for a response.
    _An asynchronous request-response relationship is one where the client sends a request, but control returns right away, so it can continue its processing on another need. None of this processing can depend on the response from the server. Once the server has completed the request, a message is sent to the client, which will have a handler to process the response. In UML, an asynchronous message is depicted with a line-arrowhead.
_   Client requests are often designed to run asynchronously, because it is often preferable to have clients be responsive for other tasks even if they are waiting for information from the server. Limiting client/server relationships to request/response messaging patterns allows for systems that can be scaled more easily by adding clients. Clients and servers are extensible, because as long as a server receives a message it knows, it will respond. The source of the message is not important to the server, so many clients can be added as needed.
_   n-Tier architecture can take on different numbers of tiers, based on separation of concerns. Additional tiers can be added to the system for specific purposes.
_   In a three-tier architecture, where a tier
is inserted between the database and end users. This tier is often referred to as a middle layer, a business layer, or an application layer—its name depends on its main responsibility. The middle layer will be a client of the database, and a server for the client application software on the end users’ devices. Middle tiers help determine how or when data can be changed, and in what ways. Having a middle layer allows client application software to be thinner, as it can be focused on presentation only. This makes it easier to maintain.
_   Two potential drawbacks of n-Tier architecture include:
    _It requires extra resources to manage the client/server relationships. If more tiers are added, there are more machines or processes to manage, with different communication protocols. This makes a system more complex, and therefore more difficult to change and maintain.
    _A server acts as a central point of failure. Systems may have backups or mirrors, but it can take time to switch to these backups and recover the server. Redundant servers are possible but add complexity.
_   The advantages of n-Tier architecture are notable, however, and contribute to its common use in the software industry:
    _n-Tier architecture is very scalable. Clients can continue to be added as long as a server can handle all the requests it receives in a reasonable time.
    _Centralization of functionality allow for data to reside on one machine but to be accessible by any machine on the same network.
    _Centralization of computing power allows client machines to require less processing power. Companies can thus offer processing power as a service, which is more practical and cost effective.
    _n-Tier architecture supports separation of concerns. Middle layers can take the role of managing application logic and accessing the database directly. Adding tiers can further allow for loose coupling and levels of abstraction, making a system that is easier to change and extend.
_   When a system can be split into service roles and request roles, a client/server architecture should be considered.

3.2.6 – Interpreters
Interpreter-based systems allow end users to write scripts, macros, or rules that access, compose, and run the basic features of those systems in new and dynamic ways. It provides users with flexible and portable functionality that can be applicable in a variety of commercial systems.
_   Interpreters can run scripts and macros. Scripts are often used for automating common tasks, such as scheduling tasks, performing repetitive actions, and composing complex tasks that invoke other commands. Macros are an evolution of scripts that became popular with the introduction of graphical user interfaces. A macro records keyboard and mouse inputs, so they may be executed later. 
_   Interpreter-based systems encourage end users to implement their own customizations. This is further supported by systems that offer an easier-to-use language with domain-specific abstractions suited to the needs and thinking of the end users. End users do not have to know the programming languages used in developing the software in order to customize the system for their needs.
_   Interpreter-based systems offer certain advantages. In particular, interpreters make systems more portable, so they can work on platforms that the interpreter supports. This is an important feature with the growth of virtual machines and virtual environments—more and more services are being hosted in the cloud.
_   However, interpreter-based systems also offer certain disadvantages. Interpreters can be slow. Basic implementations spend little time analyzing the source  code and use a line-by-line translate and execute strategy. This is a trade-off: it may be faster and more flexible for developers and end users to use an interpreted language, but slower for computers to execute interpreted code.
_   Java also uses interpreters!. In Java, programs are first translated into an intermediate language that is loaded into a Java Virtual Machine (JVM), which executes the intermediate language. The JVM will attempt to optimize the intermediate instructions by monitoring the frequency at which instructions are executed. The instructions that are executed frequently get translated into machine code and executed immediately. On the next execution of the same intermediate instructions, the JVM uses lazy linking to point the program to the previous machine code translation. Instructions that are not used frequently are left for the interpreter of the JVM to execute. This decreases execution time since frequently used instructions do not need to be constantly translated and the entire program does not need to be translated all at once. The JVM also provides portability to Java programs, allowing them to run on many operating environments.

3.2.6a – State Transition Systems
Is a concept used to describe the behavior of a system. More precisely, all potential behaviors of a system. Even if a specific system state has a low probability of being seen, a state transition system will still describe how that state can be arrived at if it is an expected behavior of the system.
_   State transition systems are a complex topic in computer science and they play  an important role in helping software architects and software engineers understand how different states can be achieved.
_   The terminology that are used when discussing state transition systems:
    _State. The information that a system remembers defines its state. For example, a queue system can be in a number of different "states": an empty state, a queued state, or a full state.
    _Transition. A transition is used to describe the change of a system from one state to another. A single system state can have multiple transitions; majority of systems today will have multiple transitions branching from one system state. This makes behaviors non-deterministic, since we cannot predict what the next state of the system will be.
    _Behavior. The behavior of a system describes what the system will do when exposed to a condition, which can vary from timed system events to user input.
    _Unlabelled state transition system is defined as a set of state, S, and transition, →, pairs that are used to describe the system's behavior. If p and q are two different states in S, then the transition between them is depicted by (p → q).
    _Labelled state transition system simple includes a set of labels, ~, with addition to the state-transition pair. Given the same states p and q in S, then the transition between the two states is shown as (p ⭇ q).
_   Unlabelled state transitions can be used for systems where the transition between all states are the same. For example, your system could respond to a single button press that simply transitions the system sequentially from one state to the next.
_   As you can see, state transition systems can be thought of as directed graphs. Each node of the graph represents the set of states, and each edge of the graph represents the set of transition. We can determine how a system reaches a specific state by simply traversing the graph.
_   Some practical applications for state transition systems for most modern systems are complex. Consider an operating system and how it needs to manage resource allocation for a large number of processes. A state transition system can help us determine when important system events such as resources are used, what process will be using resources, and how long they will be used for. State transition systems can help us understand how parallel processing, multithreading, or distributed computing can affect the overall state of our system. Do we need to wait for another process to finish its work before continuing? At which junction of our system will we be bottlenecked?.
_   In addition, state transition systems can help us identify deadlocks. A deadlock occurs when a process is waiting indefinitely for another to release a shared resource or complete its work. A state transition system can help you easily identify deadlocks since they occur if there is a condition that prevents a transition out of particular state.
_   Modern day software continues to become more complex. Their reliance on computing techniques such as multithreading makes it more difficult to manage system resources, or determine the state that your system is in. State transition systems helps alleviate this issues by modeling the behavior of a system, and gives you a better understanding of how a system will transition from one state to another.

Dataflow Systems
involve a series of transformation on sets of data. Data is transformed from one form into another using different types of operations.

3.2.7 – Pipes and Filters
A pipe and filter architectural style has independent entities called filters, which perform transformations on data input they receive, and pipes, which serve as connectors for the stream of data being transformed.
_   Data flows in one direction, beginning at the data source and moving through a series of pipes and filters, to end at the data target. Changes to data are done sequentially from filter to filter. Each pipe serves as a connector for the stream of data. It transmits the output of one filter as input for the next filter. Each filter performs its local transformation on the data input it receives from the previous pipe and then sends the output on to the next pipe.
_   The order in which the filters transform data may change the end result. This is similar to mathematics—the order in which addition or multiplication occurs in an expression can change the end result.
_   Advantages to using the pipe and filter architecture include:
    _Loose and flexible coupling of components. In particular, this applies to filters. Each filter runs independently of other filters, which allows the easy addition of new filters, of moving filters around, or of changing individual filters in a system.
    _Filters can be treated as black boxes. Users of the system do not need to know the inner workings of each filter.
    _Reusability. Each filter can be called and used over and over again with different inputs. Filters can be repeatedly used in many different applications for different purposes.
_   Disadvantages to using the pipe and filter architecture include:
    _Reduced performance due to excessive overheads in filters. Each filter must receive input, parse that input into some data structure, perform transformations, and send data out. If every filter must do this, it is a lot of overhead, and the performance of the system will be affected as more and more filters are added.
    _Filters may get overloaded with massive amounts of data to process. If one filter is working to process large amounts of data, other filters may be waiting for inputs.
    _This architecture cannot be used for interactive applications. Applications that require rapid responses will not find this architecture suitable, as data transfers and transformations take time depending on the amount of data being transmitted.
_   Pipe and filter architectures are popular in use, such as in the UNIX operating system for text-based utilities. If different data sets need to be manipulated in a system, the pipe and filter architecture is a good choice.

Implicit Invocation Systems
In implicit invocation systems, functions are not in direct communication with each other. The event-based architectural style is one design for such a system. This style derives from the event-driven programming paradigm.

3.2.8 – Event Based
In event-based architectural styles, the fundamental elements in the system are events. Events are both indicators of change in the system and triggers to functions. Events can be signals, user inputs, messages, or data from other functions or programs.
_   Under the event-driven programming paradigm, functions take the form of event generators and even consumers. Event generators send events, and event consumers receive and process these events. A function can be both an event generator and an event consumer.
_   In the event-based architectural style, functions are not explicitly called. Instead, event consumers are based on events sent from event generators. Event-based functions experience implicit invocation, where communication between functions is mediated by an event bus. An event bus is the connector between all event generators and consumers in the system. To achieve this structure, an event and an event consumer must be bound via an event bus. This means that each event consumer registers with the event bus to be notified of certain events. When the event bus detects an event, it distributes the event to all appropriate event consumers. The event bus is a critical part of the system. The observer design pattern actually manifests the event- based architectural style.
_   One means of implementing the event bus is to structure the system to have a main loop that continually listens for events. When an event is detected, the loop calls all the functions bound to that event. This function must likely also be an event generator, because often an event consumer will have to notify other functions when it has completed its task or to send a state change. This function will implicitly invoke other functions to run after it has completed. It does this by sending out an event to the event bus. When an event reaches the event bus, corresponding event consumers will be triggered and the next computation can take place.
_   When designing your system, it is important to take into account that indirect communication between functions may not be as efficient as explicit function invocation. In event- based architectural styles, event generators do not necessarily know which functions will be consuming their events, and likewise, event consumers do not necessarily know who is generating the events they handle. This is called loose coupling, which makes it easier for systems to evolve and scale up—adding a new function requires only registering a new event-function pair to the event bus and adding a new event consumer.
_   Updating objects and data in an event-based system must also be considered. Event consumers can change shared states as they process an event if objects in the system are globally accessible. However, this allows event consumers can be called asynchronously, that is, an event consumer does not need to wait for other event consumers to finish running before running itself. Two event consumers could be running at the same time on shared data. This asynchronous design may increase efficiency of the system, but it can also result in race conditions. Race conditions mean that the correct behaviours of functions is sensitive to timing or order, so shared data may not be updated correctly.
_   Functions can be coordinated for access to shared data through a semaphore. A semaphore is a variable or abstract data type that toggles between two values, available and unavailable, and that is used to control access to shared data. Available indicates that the shared data is not in use, and unavailable indicates that the shared data is in use by a function.
_   If an object is not globally accessible and its state is changed by an event consumer, then some indication must be sent back to the event bus before the function ends. Event consumers can thus be aware of the state change to that event.
_   In event-based architectural styles, events and functions do not behave in a predictable way. There is no guarantee of exactly when an event will be handled, how long it will take to handle, or when an event generator will emit an event. Control flow is thus based on which events occur during its execution and in what order.
_   Event-based architecture styles are well suited to interactive applications. Graphical user interface applications that rely on user input and distributed systems that interact with other programs are prime candidates for this style.

S2 - 3.2.8a – Publish–Subscribe
_   There are two important differences that differentiate the publish-subscribe architectural style from the event-based architectural style:
    _First, unlike the the event-based architectural style, the components are either publishers or subscribers. Publishers send messages, while subscribers can subscribe or unsubscribe to receive these messages. A component cannot be both a publisher and a subscriber.
    _Second, the relationship between the publisher and the subscribers may vary in form and closeness.
_   Like the event-based architectural style, the publish-subscribe architectural style relies on implicit invocation. Publishers and subscribers are not explicitly connected, but instead, there is a loose coupling between them. In a simple implementation of the publish-subscribe architectural style, to receive messages, a subscriber registers their interest to publishers through a call-back. Publishers maintain a list of subscribers and communicate to them through procedure calls to the registered call-backs. In this way, subscribers are informed of messages implicitly.
_   This implementation is well suited to applications where each publisher has a relatively small number of subscribers. Every time a new message is ready to be published, the publisher makes a procedure call to each subscriber to deliver the new message. This can become a lot of work for the publisher as the number of subscribers grows.
_   Alternatively, the publish-subscribe architectural style can be adapted to deal with large scale applications, where a single publisher may have many subscribers, by designing a system with more loosely coupled components. This is achieved by introducing a connector to distribute and possibly filter the messages to the subscribers. The connector could be an event bus or a network protocol. The connector creates more distance between publishers and subscribers and relieves work for the publisher. These connectors may provide complex filtering of messages before they are delivered to the subscribers.
_   If an event bus is used as a connector, the system would be similar to the event-based architectural style, in that subscribers register with the event bus to receive messages from a particular publisher, and the publisher sends messages to the event bus for delivery to its subscribers. Because the event bus mediates communication, publishers may not be aware of the subscribers. However, remember there is an important difference here in the publish-subscribe architectural style, publishers can only send messages, not receive them, and subscribers can only receive messages, not send them.
_   Conclusion:
    _The flexible loose coupling between publishers and subscribers makes publish-subscribe systems scalable and flexible.
    _While designing your system, it’s important to consider that using this architectural style may make it impossible to modify a published message. Since each subscriber has their own copy of the message, a correction message may be the only way to convey a change.
    _Some example systems that can manifest this style are mailing lists, RSS feeds, and mobile messaging subscriptions.

3.2.9 – Process Control
Process control is important in many processes to ensure efficient and safe operations.
_   Feedback Loops: is one of the most basic forms of process control. It has four basic components: a sensor, a controller, an actuator, and the process itself. The sensor monitors some kind of important information. The controller is the logic of the system. The actuator is the physical method of manipulating the process. The process is what is trying to be controlled.
    _   In a feedback look, the controller logic must run continuously. This is because the process is always changing. The frequency, or how often the loop runs, depends on the desired level of control and the sensitivity of the system. For example, room temperature changes slower compared to other processes, so it is not necessary or useful to have a high frequency, such as every microsecond.
    _   Feedback loops can often be improved. Consider the example above of room temperature. Let us improve that loop by introducing a proportional controller. A proportional controller calculates an error value as the difference between the desired setpoint and a measured process variable and then applies a correction based on proportion. In this case, a heating vent whose position can be controlled could read an error, and open the vent according to how big the error signal is. As the temperature comes closer to the setpoint, the heating will slow down so that the setpoint can be approached gradually. (Proportional controllers can also have undesirable effects, but this runs outside the scope of this course.)
_   Other variations exist on process control: A feedback loop is an example of a closed loop, as information from the process is used to control the same process. An open loop is one where the process is controlled without monitoring the process. Open loops cannot deal with changes in the process or check itself to see if it is succeeding.
_   Feedforward control occurs in systems with processes in series. Information from an upstream process can be used to control a downstream process. Feedforward control requires a good model of how process response and deals with unknown events. These systems are often used in conjunction with feedback loops.
    _For example, a flood protection system could use feedforward control. If an upstream monitoring station detects large flow rates, then the controller for the flood protection system could be signalled. The controller asks the actuator, a gate, to open and divert water into a reservoir to keep water levels manageable.
_   More complex problems will have many sensors and ways to control the process. Process control architecture for complex problems will therefore be more complex. For a complex example an architecture based on a MAPE-K structure, which has four major steps: monitor, analyze, plan, and execute. All four of these steps must have knowledge of the process. This knowledge is in the form of a model of the system. Such models should be designed in close conjunction with engineers specializing in the process.
_   Knowledge is very important in MAPE-K systems, particularly complex ones. Currently, technology companies are investing heavily in such systems, due to the advent of machine learning and big data. This investment goes towards real-world testing, machine learning, and data modelling in order to operate these systems. Effective software architecture is key. Even though it is handled by specialized professionals, it is important to be aware of process control. Software is becoming a bigger part of controlling physical systems.

3.3.1 – Quality Attributes
Quality attributes are measurable properties of a system used to gauge a system’s design, run-time performance, and usability.
_   Software architecture aims to combine software design patterns and principles in order to define the software’s elements, their properties, and how the elements interact with each other. This suggests that these elements alone can determine the capabilities and the quality of software architecture. However, as design patterns address only a specific problem and not all business needs, this is not the case. Modern systems need to be able to focus on a wide range of problems, not just technical issues.
_   Individual design patterns and principles are concerned primarily with functional software issues, while software architecture considers functional and non-functional requirements. Software architecture must address the big picture. Architecture sets guidelines for design patterns and principles in order to ensure conceptual integrity and consistency throughout.
_   Software architecture does not have inherent qualities that make it “good architecture” or “bad architecture.” Instead, software architecture is designed to address a set of requirements. Requirements are used to address a problem or need. Further, different architectures are meant to be used in different environments and contexts. This means that an architecture isn’t bad in some cases, but rather just be incorrect for the context it is being used in.
_   Most systems use a combination of architectural designs. The requirements for modern systems are complex, and there may not be a clear-cut software architecture that can address all of them. This is particularly true for non-functional requirements, which are not always clear or explicitly presented by clients and stakeholders. Non-functional requirements can also vary between different stakeholder groups. For example, an end user may not care about testability, while a development group will.
_   If system architectures are not measured as inherently good or bad, there must be a way to determine if the architectural design is capable of meeting system requirements. This quality of a system is determined by quality attributes. For an attribute to be measurable, there needs to be an objective means of quantifying it.
_   This section presents industry consensus for quality attributes. As always, context is important in evaluating what is best for your system architecture. This specialization has emphasized maintainability, reusability, and flexibility when designing and implementing systems.
_   Qualities to account for from a developer’s
perspective:
    _Maintainability: The ease at which your system is capable of undergoing changes. Systems will undergo changes throughout its life cycle, so a system should be able to accommodate these changes with ease.
    _Reusability: The extent in which functions or parts of your system can be used in another. Reusability helps reduce the cost of re-implementing something that has already been done.
    _Flexibility: How well a system can adapt to requirements change. A highly flexible system can adapt to future requirements changes in a timely and cost-efficient manner.
    _Modifiability: The ability of a system to cope with changes, incorporate new, or remove existing functionality. This is the most expensive design quality to achieve, so cost of implementing changes must be balanced with this attribute.
    _Testability: How easy it is to demonstrate errors through executable tests. Systems should be tested as tests can be done quickly, easily, and do not require a user interface. This will help identify faults so that they might be fixed before system release.
    _Conceptual Integrity: The consistency across the entire system, such as following naming and coding conventions.
_   Qualities from a user’s perspective:
    _Availability: The amount of time the system is operational over a set period of time. A system’s availability is measured by uptime, so it can be determined how well the system recovers from issues such as system errors, high loads, or updates. A system should be able to prevent these issues from causing downtime.
    _Interoperability: The ability of your system to understand communications and share data with external systems. This includes the system’s ability to understand interfaces and use them to exchange information under specific conditions with those external systems. This includes communication protocols, data formats, and with whom the system can exchange information. Most modern systems are interoperable and do not exist in isolation.
    _Security: The system’s ability to protect sensitive data from unauthorized and unauthenticated use. This attribute is important as most systems generally contain sensitive information. This information should be protected from those not authorized to see it, but readily available to those who have authorization. Closely associated with this is data integrity. A system should be able to control who can see the data versus who can change it.
    _Performance: The system’s throughput and latency in response to user commands and events. Performance determines how well your system is able to respond to a user command or system event. Throughput is the amount of output produced over a period of time. Latency measures the time it takes to produce an output after receiving an input. This attribute has a major influence on architecture due to its importance to users. It is better to have a lower price per unit of performance. With the advancements in technology, this ratio has been steadily decreasing.
    _Usability: The ease at which the system’s functions can be learned and used by the end users. Usability determines how well your system is able to address the requirements of end users. In order to have high usability, your system needs to be easy and intuitive to learn, minimize user errors, provide feedback to the user to indicate that the system has registered their actions, and make it easy for the user to complete their task.
_   A high-quality system does not need to be “complex.” An overly complex system makes it difficult and time consuming to produce. It is good practice to try to minimize complexity in the design. If a simpler architecture can satisfy all the system requirements and achieve a high-quality design while needing less time and less money, it makes sense to go with that.
_   It is important to have detailed and up-to-date documentation of a system. In fact, this is part of a high-quality system. This helps record and share an architectural vision. The documentation keeps a design cohesive, should the architect or any of the developers leave the team.
_   Creating a high-quality system architecture should be methodical and use a set of rules or guidelines for the design process. Although every company will have some specific design rules or system structure rules, some should be common sense.
_   Design process guidelines include:
    _Recognizing the important of quality attributes and prioritizing them for each system being designed. Quality attributes should be kept up to date throughout the life cycle of the system. Trade-offs and details of how a system will meet qualities should be noted.
    _Involving a technical lead in the design process. Although architectural design can be applied to many different technologies, involving a technical lead will help identify any implementations that may pose a challenge, which may need to be re-considered in the design.
    _Taking a design approach from the perspective of different groups of stakeholders.
_   Structural rules that ensure there is conceptual integrity when implementing the system include:
    _Having well-designed subsystems that are assigned  responsibilities based on design principles. Remember that subsystems should use design principles such as separation of concerns.
    _Having consistent implementation of functions across the entire system. If the same task needs to be achieved by two or more subsystems, then consider how implementation can be reused.
    _Having a set of rules on how resources are used. Resources may include memory, bandwidth, or threads that the system has access to.
_   In summary, when selecting the appropriate architecture for the problem at hand, it is important to involve all groups of stakeholders in the design of the system, to adopt good documentation practices, and to set rules for design and implementation.
_   A well-designed system considers quality attributes from a developer’s perspective, which includes maintainability, reusability, flexibility, modifiability, testability, and conceptual integrity; the system should also consider attributes from a user’s perspective, which includes availability, interoperability, security, performance, and usability.

3.3.2 – Analyzing and Evaluating an Architecture
In addition to designing a system, it is important to know how to evaluate the design to determine if it addresses the concerns, or the requirements, of all stakeholders. Analyzing and evaluating software architecture can be difficult due to the abstract nature of software. 
_   In order to measure quality attributes, quality attribute scenarios can be used to determine if a system is able to meet requirements set for the attribute. There are two kinds of scenarios:
    _A general scenario, which is used to characterize any system.
    _A concrete scenario, which is used to characterize a specific system
_   Both general and concrete scenarios have:
    _A stimulus source, which is anything that creates a stimulus. It can be internal or external to the system.
    _A stimulus is a condition that will cause the system to respond. As the source of the condition can originate internally or externally, types of conditions will need to be differentiated.
    _An environment is the mode of the system when it is receiving a stimulus. This is an important aspect, particularly if the system involves distributed computing, or if it can exist in operational modes besides just running and stopped, like recovering from a failure.
    _An artifact is the part of the system that is affected by the stimulus. In large-scale systems, a stimulus should not directly affect the entire system.
    _A response is how the artifact will behave as a result of receiving a stimulus. This response could include handling an error, recovering from a failure, updating system logs, dispatching security alerts, or changing the current environments.
    _A response measure is a metric used to quantify the response so that the quality attribute can be measured. The metric should be quantitative and objective, such as probability of failure, response time, repair time, and average system load.
_   Scenarios are built to identify situations that impact the quality attributes of a system. In the context of analyzing and evaluating architecture, you should focus on situations that are outside of the normal execution path. This means that scenarios involving incorrect input, heavy system loads, or potential security breaches should be prioritized highly.
_   It is a system’s “inability” to handle unexpected failures that stops it from achieving a specific quality attribute.
_   In a general scenario, high-level events are summarized. As a single scenario may involve many component values, it often summarized in a table. Concrete scenarios are more focused. They can help you test an architecture with a specific stimulus under specific system environments and measure how well the system can respond.

Architecture Trade-off Analysis Method (ATAM):
 There are a number of methods that can be used to implement scenarios in analysis and evaluation of the entire architecture. This section will focus on an evaluation technique developed by the Software Engineering Institution at Carnegie Mellon University known as Architecture Trade-off Analysis Method (ATAM).
_   With ATAM, evaluators do not need to be familiar with the architecture or the problem space. A system can be evaluated by outsiders.
_   There are three different groups of participants in ATAM:
    _The first is the evaluation team. This has three different subgroups: designers, peers, and outsiders. Evaluation teams must be unbiased.
        _Designers are the subgroup involved with architectural design. They naturally follow iterative, hypothesis-driven methods when designing, including analyzing systems requirements, creating a design to address those requirements, and reviewing the design.
        _Peers are the subgroup composed of those who are part of the project, but they are not involved in the design process. Their point-of-views helps round out design decision.
        _Outsiders are the subgroup composed of those external to the project or organization. Involvement of outsiders helps eliminate bias towards the project in evaluation. Outsiders should have experience and expertise in analyzing architecture.
    _Project decision makers are a participant group of project representatives with the authority to make project decisions. This could include project managers, clients, product owners, software architects, and technical leads.
    _Architecture stakeholders are a participant group of those who want the architecture to successfully address business needs, but who are not actively involved in the evaluation process. This could include end users, developers, and support staff.
_   In an ATAM, a software project is initiated when business drivers identify a need for a system to address some problem. Business drivers go hand in hand with the system architecture, which is created as the solution to the business issues. Together, business drivers and system architecture determine the quality attributes of the system, the architectural approach taken, and the design decisions that are made. These combine together to create quality attribute scenarios.
_   Scenarios can then be analyzed, resulting in an evaluation of the system, which includes trade-offs, sensitivity points, non-risk scenarios, and risk scenarios. Since the risk scenarios have a negative impact on the quality of the system, each of them are analyzed and categorized into “risk themes.”
_   The entire ATAM process itself can be broken down into nine steps:
    _1. Present the ATAM: The evaluation team presents the ATAM process. This includes: the context for the evaluation, expectations, procedures, outputs, and addresses any concerns about the evaluation.
    _2. Present the business drivers: The project decision makers present the business problem and the goals for the system as well as the system’s features and requirements, project constraints, and scope.
    _3. Present the architecture: Both current and expected state of the architecture is presented as  well as constraints such as time, cost, difficulty of the problem, and quality expectations.
    _4. Identify the architectural approaches: This analysis activity involves examining the architectural patterns that have been used in the system. This step analyzes the documentation and the notes from presentations and asks questions to gain more clarity about the system.
    _5. Create a quality attribute tree: A quality attribute utility tree is created, which maps the quality-related architecturally significant  requirements (ASR)s for each quality attribute. ASRs arise from the business drivers. To build such a tree, the overall “utility” of a system is broken down into quality attributes, which are refined into attribute refinements. Attribute refinements are more specific qualities of a system. Once the quality attributes have been refined, ASRs can be associated with the appropriate attribute. This step provides insight into the system and identifies quality priorities. This step should be conducted in conjunction with project decision makers. In quality attribute trees, ASRs are given priority values to denote if they are “must-haves” or not.
    _6. Analyze the architectural approaches: Using the prioritized ASRs from the utility tree, examine the architecture and determine how it addresses each ASR. This allows for the identification and documentation of risk and non-risk scenarios, sensitivity points, and trade-offs. This step reveals the capabilities of the system and consequences of design decisions. It is not meant to be comprehensive, but it identifies connections between business drivers and system architectures.
    _7. Brainstorm and prioritize scenarios: In this step, each group of participants creates quality attribute scenarios that are important to them, which they would expect when using the system. Scenarios with similar quality concerns or behaviours can be merged. This step provides an overview of the day-to-day system usage and insights into the environment that the system can be in. Scenarios are prioritized based on importance to each stakeholder, and the evaluation team compares the list with the prioritized ASRs in the utility tree. If the priorities of the stakeholders match closely with the priorities in the utility tree, then there is good alignment. There is a risk if there are many additional scenarios discovered during this step that were not in the original set of ASRs. It is an indication that the architecture is not able to address the needs of stakeholders.
    _8. Re-analyze the architectural approaches: Recreate a utility tree, but this time, using the top five to ten scenarios prioritized in the previous step. This new tree can be used to talk with the system architect and discover how each scenario can be achieved with the system design.
    _9. Present the results: Results of the evaluation are compiled together. This includes all architecture documents, utility trees, risk and non-risk scenarios, sensitivity points, trade-offs, and risk themes. Risk scenarios should be grouped together by risk theme. Risk themes help identify which business drivers are affected.
_   ATAM helps expose unseen risks for stakeholders involved in the architectural process.
_   Modern systems are becoming more and more complex, and creating an architecture that can achieve all the requirements for quality attributes is becoming increasingly important. Being able to evaluate and analyze architectures helps successfully create high- quality systems.
_   ATAM is a common method for analyzing and evaluating architectures, especially as it does not require evaluators to have intimate knowledge of the system, and covers the viewpoints of all important stakeholders. ATAM helps minimize risks in a system by identifying them and helps architects minimize the effects of sensitivity points and be sensible about trade-offs.
_   ATAM also helps facilitate communication between stakeholders, including identifying issues with newly discovered functionalities that the stakeholders expressed to be important.

3.3.3 – Relationship to Organizational Structure
A study from the Harvard Business School showed that looser organizational structures, such as in open-source projects, led to more loosely coupled modular code (MacCormack, Rusnak, & Baldwin, 2007). On the other hand, in-house development teams tended towards tighter coupling. They suggest that this difference could be due to conscious choices by the developers or just a natural consequence of the environment in which the software is developed. This study supports Conway’s Law. This law states that a software system will tend to take a form that is congruous to the organization that produced it.
_   This law should be taken into consideration when putting a software development team together. Rather than bringing a team together to work on a project with constant communication that can lead to a tightly coupled system, knowledge of Conway’s Law should result in planning development teams around the desired architecture. Many programmers know Conway’s Law explicitly or intuitively.
_   When putting together a team of developers, it is a good idea to first plan the architecture that works best for the system and organize the team around that architecture. For example, if you are building a web application using the n-Tier architecture, you could have one team for the data backend, one team for the application logic layer, and one for the presentation tier.
_   This increases the importance of flexibility in design, as there may be cases where implementation of a component is not yet known or may change. Conway’s Law  ay entail extra work to provide unified and scalable architectures. There may be need of a team whose purpose is to consolidate and enforce common services across the whole system.















































 